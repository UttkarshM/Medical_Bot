{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7936e30c-aba0-42f3-abcf-67855945db7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /home/uttkarsh/anaconda3/envs/envi/lib/python3.10/site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf835336-6b96-4aba-a0db-f56ec2a1fce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /home/uttkarsh/anaconda3/envs/envi/lib/python3.10/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9bd2003-b9a3-44a5-8478-c75eb67fb768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ea8f197-9800-4a78-8761-05171eaa65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import transformers\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig, GemmaTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import load_qa_chain\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da260d9f-a3cd-46d5-beb5-cc18c35bf72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uttkarsh/anaconda3/envs/envi/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32d32a1415f450d973b93119ab6dfda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba52d2c133424b37b367da1382ca2b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62fa017d6494fe381de942155f9f81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a068ac6389d0444b98d5e7f0ed1be3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c1c651a997452699de501252755110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# os.environ['HF_TOKEN']=userdata.get('HF_TOKEN')\n",
    "model_id = \"google/gemma-2b\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_id,token=os.environ['HF_TOKEN'])\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             device_map={\"\":0},\n",
    "                                             token=os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5425eaa5-3f6c-43b6-8f18-3925315ffa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['depression.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f421012-bfc1-439b-a3e0-24f019b5e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_text(pdf_docs):\n",
    "    text=\"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader= PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text+= page.extract_text()\n",
    "    return  text\n",
    "\n",
    "\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def get_vector_store(text_chunks):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
    "    vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "\n",
    "def get_conversational_chain():\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
    "    provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
    "    Context:\\n {context}?\\n\n",
    "    Question: \\n{question}\\n\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             temperature=0.3)\n",
    "\n",
    "    prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])\n",
    "    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "\n",
    "    return chain\n",
    "\n",
    "\n",
    "\n",
    "def user_input(user_question):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "    \n",
    "    new_db = FAISS.load_local(\"faiss_index\",embeddings,allow_dangerous_deserialization=True)\n",
    "    docs = new_db.similarity_search(user_question)\n",
    "\n",
    "    chain = get_conversational_chain()\n",
    "\n",
    "    \n",
    "    response = chain(\n",
    "        {\"input_documents\":docs, \"question\": user_question}\n",
    "        , return_only_outputs=True)\n",
    "\n",
    "    print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54616551-9426-4c1c-98a9-a542f24028c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=get_pdf_text(var)\n",
    "chunks = get_text_chunks(text)\n",
    "get_vector_store(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c00887da-3ec9-4860-a415-2975703f1d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_text': 'The provided context does not mention anything about Star Wars, so I cannot answer this question from the provided context.'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The provided context does not mention anything about Star Wars, so I cannot answer this question from the provided context.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    res = user_input(\"how is star wars\")\n",
    "    print('\\n\\n\\n\\n')\n",
    "    print(res['output_text'])\n",
    "except:\n",
    "    print(\"answer not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b557156-e35d-4144-86ec-6d4b687fded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depression treatment typically involves medication, psychotherapy, or both. If these treatments do not reduce symptoms, brain stimulation therapy may be another treatment option. In milder cases of depression, treatment might begin with psychotherapy alone, and medication added if the individual continues to experience symptoms. For moderate or severe depression, many mental health professionals recommend a combination of medication and therapy at the start of treatment.\n"
     ]
    }
   ],
   "source": [
    "print(res['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1df824-502e-437a-875c-39964f21acc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aae1c9-4be5-4fad-a70e-3f70a9afb529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
